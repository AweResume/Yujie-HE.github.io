[{"authors":["admin"],"categories":null,"content":"I am currently a senior undergraduate in pursuit of a B.Eng. Degree in mechanical engineering with specialization in mechatronics.\n\u0026lsquo;Diversity is essential to happiness\u0026rsquo; by Philosopher Bertrand Russell is my life motto. Thus, I devoted myself to realizing intelligent sensing \u0026amp; control in both industrial projects and academic researches during my bachelor studies.\nFrom Aug 2018, I have started my academic exploration as an apprentice researcher in Vision4Robotics Group, Tongji University, supervised by Prof. Changhong Fu. I have a keen interest in robotic vision, with a focus on the incorporation of the state-of-the-art machine learning techniques into vision perception \u0026amp; processing.\nCurrently, I am applying for a Master or PhD program in the areas of robotics and computer vision. You can find my latest CV here.\n Due to the rebuilding of this personal website, more content is to be updated in following days !\n ","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://yujie-he.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am currently a senior undergraduate in pursuit of a B.Eng. Degree in mechanical engineering with specialization in mechatronics.\n\u0026lsquo;Diversity is essential to happiness\u0026rsquo; by Philosopher Bertrand Russell is my life motto. Thus, I devoted myself to realizing intelligent sensing \u0026amp; control in both industrial projects and academic researches during my bachelor studies.\nFrom Aug 2018, I have started my academic exploration as an apprentice researcher in Vision4Robotics Group, Tongji University, supervised by Prof.","tags":null,"title":"Yujie He","type":"authors"},{"authors":["Changhong Fu","Yujie He","Fuling Lin","Weijiang Xiong"],"categories":null,"content":"\nMain structure of the proposed tracking approach\n\n","date":1575504000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575504000,"objectID":"77d0331b7cb39d736266ef83aedbf671","permalink":"https://yujie-he.github.io/publication/2019_mkct_ncaa/","publishdate":"2019-12-05T00:00:00Z","relpermalink":"/publication/2019_mkct_ncaa/","section":"publication","summary":"In recent years, the correlation filter (CF)-based method has significantly advanced in the tracking for unmanned aerial vehicles (UAV). As the core component of most trackers, CF is a discriminative classifier to distinguish the object from the surrounding environment. However, the poor representation of the object and lack of contextual information have restricted the tracker to gain better performance. In this work, a robust framework with multi-kernelized correlators is proposed to improve robustness and accuracy simultaneously. Both convolutional features extracted from the neural network and hand-crafted features are employed to enhance expressions for object appearances. Then, the adaptive context analysis strategy helps filters to effectively learn the surrounding information by introducing context patches with the GMSD index. In the training stage, multiple dynamic filters with time-attenuated factors are introduced to avoid tracking failure caused by dramatic appearance changes. The response maps corresponding to different features are finally fused before the novel resolution enhancement operation to increase distinguishing capability. As a result, the optimization problem is reformulated, and a closed-form solution for the proposed framework can be obtained in the kernel space. Extensive experiments on 100 challenging UAV tracking sequences demonstrate the proposed tracker outperforms other 23 state-of-the-art trackers and can effectively handle unexpected appearance variations under the complex and constantly changing working conditions.","tags":["Visual tracking","Unmanned aerial vehicles","Multi-kernelized correlators","Adaptive context analysis","Dynamic weighted filters"],"title":"Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters","type":"publication"},{"authors":["Fuling Lin","Changhong Fu","Yujie He","Fan Li"],"categories":null,"content":"\nThe visualization of maximum values on different feature response maps.\n\n","date":1573776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573776000,"objectID":"5282dfadfd7d08c8fadb867603e6c049","permalink":"https://yujie-he.github.io/publication/2020_tot_preprint/","publishdate":"2019-11-15T00:00:00Z","relpermalink":"/publication/2020_tot_preprint/","section":"publication","summary":"Correlation filter (CF)-based trackers have recently de-livered high performance in diverse applications for un-manned aerial vehicles (UAVs). The specific challenges in UAV tracking scenarios pose difficulties in traditional CFs, including camera/object fast motion, viewpoint variations, and background clutter. Most existing approaches employ multiple features to encode the CF but ignore the relevance among these features. Consistency of inter-feature responses limiting CF discriminant power has not been fully explored, especially in complex tracking situations. In this work, a target-oriented UAV tracking approach is proposed to associate various features and repress the difference among responses for better encoding capability. To further ensure the multi-feature response consistency with more focus on the tracked object, the target-oriented regularization is introduced in the optimization problem. Comprehensive experiments on four datasets (UAV123, UAV123@10fps, DTB70, UAVDT) containing 366 sequences with over 200K images show that the proposed TOT method outperforms the other 20 state-of-the-art trackers favorably in accuracy and robustness. For tracking efficiency, TOT achieves a real-time speed of 50 FPS on a single CPU, which can be efficiently applied in UAV onboard processors.","tags":["Visual tracking","Unmanned aerial vehicles","Multi-feature Inconsistency Mining"],"title":"TOT: Target-oriented UAV Tracking via Multi-feature Inconsistency Mining","type":"publication"},{"authors":[],"categories":[],"content":"First time to participate the top robotics conference\u0026mdash;IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019) held on Nov. 4 – 8, 2019 in Macau, China.\nFeel very lucky to talk to the experts, professors, and my fellows!\nOur paper \u0026lsquo;Sample Purification-Aware Correlation Filters for UAV Tracking with Cooperative Deep Features\u0026rsquo; is accepted by the Workshop on Fast Neural Perception and Learning for Intelligent Vehicles and Robotics and won the Best Poster Award!\nFor more details, please refer to SPCF!\n\nMy first time to attend IROS2019 @ Macau\n Keynote by Davide Scaramuzza covering Autonomous Drones Event Cameras \n\n","date":1572840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572840000,"objectID":"b06a9c527d705b63f1d8f86cf734ca2c","permalink":"https://yujie-he.github.io/post/19-11-iros/","publishdate":"2019-11-04T12:00:00+08:00","relpermalink":"/post/19-11-iros/","section":"post","summary":"First time to participate the top robotics conference\u0026mdash;IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019) held on Nov. 4 – 8, 2019 in Macau, China.\nFeel very lucky to talk to the experts, professors, and my fellows!\nOur paper \u0026lsquo;Sample Purification-Aware Correlation Filters for UAV Tracking with Cooperative Deep Features\u0026rsquo; is accepted by the Workshop on Fast Neural Perception and Learning for Intelligent Vehicles and Robotics and won the Best Poster Award!","tags":["conference"],"title":"Our paper SPCF won the Best Poster Award in the IROS Workshop 2019!","type":"post"},{"authors":["Fuling Lin","Changhong Fu","Yujie He","Fuyu Guo","Qian Tang"],"categories":null,"content":"\nComparison between discriminative correlation filter (DCF) and the proposed BiCF\n\n","date":1568505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568505600,"objectID":"e630d1a4757c9a5a5fff05c0aaa4e9ef","permalink":"https://yujie-he.github.io/publication/2020_bicf_preprint/","publishdate":"2019-09-15T00:00:00Z","relpermalink":"/publication/2020_bicf_preprint/","section":"publication","summary":"Correlation ﬁlters have shown excellent performance in unmanned aerial vehicle (UAV) tracking scenarios due to their high computational efﬁciency. During the UAV tracking process, viewpoint variations are usually accompanied by changes in the object and background appearance, which poses a unique challenge to CF-based trackers. Since the appearance is gradually changing over time, an ideal tracker can not only forward predict the object position but also backtrack to locate its position in the previous frame. There exist errors in the reversibility of the tracking process, which contains the information on the changes in appearance. However, some existing methods do not consider the forward and backward errors while using only the current training sample to learn the ﬁlter. For other ones, the applicants of considerable historical training samples impose a computational burden on the UAV. In this work, a novel bidirectional incongruity-aware correlation ﬁlter, i.e., BiCF tracker, is proposed. By integrating the bidirectional incongruity error into the CF, BiCF can efﬁciently learn the changes in appearance and suppress the inconsistent error. Extensive experiments on 243 challenging image sequences from three UAV datasets (i.e., UAV123, UAVDT, and DTB70) are conducted to demonstrate that the proposed BiCF tracker favorably outperforms other 25 state-of-the-art trackers and achieves a real-time speed of 45.4 FPS on a single CPU, which can be applied in UAV efﬁciently.","tags":["Visual tracking","Unmanned aerial vehicles"],"title":"BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking","type":"publication"},{"authors":["Yujie He","Changhong Fu","Fuling Lin","Yiming Li","Peng Lu"],"categories":null,"content":"\nThe overview of TACF tracker\n\n","date":1568505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568505600,"objectID":"c25f0095de5beeac021aa6d71c67c013","permalink":"https://yujie-he.github.io/publication/2020_tacf_preprint/","publishdate":"2019-09-15T00:00:00Z","relpermalink":"/publication/2020_tacf_preprint/","section":"publication","summary":"Object tracking has become a demanding task for booming unmanned aerial vehicle (UAV) applications in recent years. Although correlation filters (CF) based tracking methods show competitive performance in classic tracking benchmarks, those trackers cannot adequately cope with the dramatic appearance changes caused by the rapid flight of UAV in mid-air. What is more, with limited interpretation to training samples, traditional methods might be easily over-fitted, and lack of local attention ability which undermine the performance as well. Unlike previous works using features fusion or dynamic masking, a practical and straightforward tri-attention strategy is proposed to refine responses and filters learning adaptively. Specifically, three attention strategies are proposed on top of CF-based methods, which model the semantic interdependencies in position, dimension, and surrounding context, respectively. Besides, they can be integrated into correlation filter frameworks for more precise tracking because of lightweight and generality. Through extensive experiments on 173 challenging UAV image sequences, the proposed tracker demonstrates competitive tracking accuracy and robustness, achieving better performance than other 12 state-of-the-art trackers under challenging situations.","tags":["Visual tracking","Unmanned aerial vehicles","Attention mechanisms"],"title":"Tri-Attention Correlation Filter for Effective UAV Object Tracking","type":"publication"},{"authors":["Changhong Fu","Fuling Lin","Fan Li","Yujie He"],"categories":null,"content":"\nComparison between traditional CF-based and proposed SPCF tracker\n\n","date":1567209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567209600,"objectID":"885aa35a9654e3a8444e0e183be373c5","permalink":"https://yujie-he.github.io/publication/2019_spcf_irosw/","publishdate":"2019-08-31T00:00:00Z","relpermalink":"/publication/2019_spcf_irosw/","section":"publication","summary":"Correlation Filters (CF) have recently demonstrated promising performance in terms of rapidly tracking objects for unmanned aerial vehicles (UAV) in different types of UAV tracking tasks. The strength of the approach comes from its ability to learn how the object is changing over time efficiently. However, due to heavy dependence on the quality of the training set and the lack of real negative training samples, the object appearance model may be easily interfered by the corrupted training samples, which can result in suboptimal performance. Besides, limited by the representation of a single feature, the tracking model may fail to cope with the complex surrounding environment and considerable appearance variation of the object. In this work, the principal causes behind the problems of the abundance of object representation and purity of training samples have been tackled, to simultaneously improve both discriminative power and anti-disturbance capability of the tracking model. Comprehensive experiments on 100 challenging UAV image sequences have demonstrated that the novel sample purifying tracker based on cooperative features learning, i.e., SPCF tracker, outperforms 15 state-of-the-art trackers in terms of efficiency, robustness, and accuracy. To the best of our knowledge, the presented SPCF tracker is designed for object tracking and employed in UAV tracking tasks for the first time.","tags":["Correlation filter","Unmanned aerial vehicles","Sample purification"],"title":"Sample Purification-Aware Correlation Filters for UAV Tracking with Cooperative Deep Features","type":"publication"},{"authors":null,"categories":null,"content":" Teaching Assistant from Sep. 2018 - Jan. 2019\n  Assisted first-year students major in Industrial Design to get started Arduino Hardware and Programming\n Designed a series of the electromechanical modules for Industrial Design students\n Gave lectures on basic mechanical principle with Arduino hardware and programming and advanced RGBD sensors for the semester project\n  The following video is Mechatronics Module Experiments.\n\n \n","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"5fb85218b7c762be752eebb403211af0","permalink":"https://yujie-he.github.io/project/2019-tongji-ta/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/project/2019-tongji-ta/","section":"project","summary":"Acted as TA for freshmen in [College of Design \u0026 Innovation](http://tjdi.tongji.edu.cn/)","tags":["Mechatronics"],"title":"Teaching Assistant in Open Source Hardware and Programming","type":"project"},{"authors":null,"categories":null,"content":" Powertrain Group Leader from Sep. 2016 - Dec. 2018\n  Designed and optimized the overall powertrain system to ensure China\u0026rsquo;s first leading four-wheel-drive Formula Student Racecar, achieving an 8\\% efficiency and 10\\% lightweight improvement Participated FSEC 2017 - 2018 and SFJ 2018 as Chief Powertrain Engineer, contributing to DIAN Racing‘s win in first place in Engineering Design and Efficiency Prize, and Best Powertrain Award from 2017 to 2018  The following video is virtual assembly of DRe18，which was what I worked for as Powertrain Group Leader.\n\n  Design Report Final @ FSEC19 \n","date":1546214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546214400,"objectID":"82d14568390f43b7be1a421e74f001ca","permalink":"https://yujie-he.github.io/project/2018-dian-racing/","publishdate":"2018-12-31T00:00:00Z","relpermalink":"/project/2018-dian-racing/","section":"project","summary":"Built First leading 4WD Formula Student Racecar in China.","tags":["Mechatronics","Racecar"],"title":"DIAN Racing Formula Student Electric Team","type":"project"},{"authors":null,"categories":null,"content":" Robotics Algorithm Development Intern from Jul. 2018 - Aug. 2018\n  Implemented sensor fusion between Pandar40 (a 40-channel LiDAR) and gyroscope and achieved a 5% accuracy improvements on top of state-of-the-art SLAM framework and drew a 3D point cloud map of Tongji University Jiading Campus below 10m Deployed control, decision, and communication algorithms for a self-developed skid steer wheel robot, realizing autonomous navigation and obstacle avoidance in a $ 300 m^2 $ workspace  \n Indoor SLAM @ Hesai\n\n Debugging the robot\n\n Jiading Campus Satellite Map corresponding to the map generated from Pandar40 \n\n","date":1546214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546214400,"objectID":"2cf2900a21859645e66bc3bb95d82458","permalink":"https://yujie-he.github.io/project/2018-hesai-internship/","publishdate":"2018-12-31T00:00:00Z","relpermalink":"/project/2018-hesai-internship/","section":"project","summary":"Implemented Outdoor SLAM @ Tongji Jiading Campus and Indoor Autonomous Navigation .","tags":["Robotics","Computer Vision","LiDAR"],"title":"SLAM and Autonomous Navigation for Skid Steer Wheel Robot","type":"project"},{"authors":null,"categories":null,"content":" Project Manager \u0026amp; Mechanical Development Leader from Oct. 2016 - Jun. 2018\n  Designed two main robots to participate in national mobile robot competition, RoboMaster, achieving lightweight and stability of the chassis and 3DOF pan-tilt mechanism and multi-robot interaction Optimized structural design to enhance operation stability and achieve lightweight, enable the robots flexible operation and combating under complicated circumstances  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"26fb77baca14eeca774e060f789d6ff1","permalink":"https://yujie-he.github.io/project/2018-super-power/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/2018-super-power/","section":"project","summary":"Designed robots to combat in RoboMaster.","tags":["Mechatronics","Robotics"],"title":"Super Power Robot Team","type":"project"}]