[{"authors":["admin"],"categories":null,"content":"I am currently a senior undergraduate in pursuit of a B.Eng. Degree in mechanical engineering with specialization in mechatronics.\n\u0026lsquo;Diversity is essential to happiness\u0026rsquo; by Philosopher Bertrand Russell is my life motto. Thus, I devoted myself to realizing intelligent sensing \u0026amp; control in both industrial projects and academic researches during my bachelor studies.\nFrom Aug 2018, I have started my academic exploration as an apprentice researcher in Vision4Robotics Group, Tongji University, supervised by Prof. Changhong Fu. I have a keen interest in robotic vision, with a focus on the incorporation of the state-of-the-art machine learning techniques into vision perception \u0026amp; processing.\nCurrently, I am applying for Master or PhD programs in the areas of robotics and computer vision. You can find my latest CV here.\n1f407a 太深 6dbdc7 太浅 58979f 不错 -- \n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://yujie-he.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am currently a senior undergraduate in pursuit of a B.Eng. Degree in mechanical engineering with specialization in mechatronics.\n\u0026lsquo;Diversity is essential to happiness\u0026rsquo; by Philosopher Bertrand Russell is my life motto. Thus, I devoted myself to realizing intelligent sensing \u0026amp; control in both industrial projects and academic researches during my bachelor studies.\nFrom Aug 2018, I have started my academic exploration as an apprentice researcher in Vision4Robotics Group, Tongji University, supervised by Prof.","tags":null,"title":"Yujie He","type":"authors"},{"authors":null,"categories":null,"content":" TJ-100685 深度学习 | Deep learning (Elective Course)  Supervised by Professor, Yin Wang\nGitHub Repo: hibetterheyj/tju_deep_learning\n Course info The course covers the following topics:\n Python basics Linear regression \u0026amp; Logistic regression NN basics Convolutional neural network Object detection Style transfer NLP basics Applicant: Medical image processing  Final Project Enhanced 3D Zonal Segmentation of the Prostate on MRI via Enhanced Weight-Standardization and GroupNorm\n基于的Weight-Standardization和GroupNorm的三维前列腺MRI区块分割\n💥For more details, please refer to jupyter notebook for final project.\nAssignments Using nbviewer for better and faster rendering!\n (1) Linear \u0026amp; (2) Logistic (multiple binary classifiers method) regression  [notebook1], [notebook2]\n (1) Logistic (softmax method) regression \u0026amp; (2) Fully connected neural network  [notebook1], [notebook2]\n Convolutional neural network implemented via (1) PyTorch \u0026amp; (2) Fastai  [notebook1], [notebook2]\n Re-implemented one style transfer algorithm (MSG-Net) via PyTorch  [notebook]\nAll assignments are available in *.ipynb. Best wishes!\n","date":1575072000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1578528000,"objectID":"e7dbb334fc015e3ac0d7250e4272c409","permalink":"https://yujie-he.github.io/study/2019-deep-learning/","publishdate":"2019-11-30T00:00:00Z","relpermalink":"/study/2019-deep-learning/","section":"study","summary":"TJ-100685 深度学习 | Deep learning (Elective Course)  Supervised by Professor, Yin Wang\nGitHub Repo: hibetterheyj/tju_deep_learning\n Course info The course covers the following topics:\n Python basics Linear regression \u0026amp; Logistic regression NN basics Convolutional neural network Object detection Style transfer NLP basics Applicant: Medical image processing  Final Project Enhanced 3D Zonal Segmentation of the Prostate on MRI via Enhanced Weight-Standardization and GroupNorm\n基于的Weight-Standardization和GroupNorm的三维前列腺MRI区块分割\n💥For more details, please refer to jupyter notebook for final project.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" TJ-100177 MATLAB及其工程应用 | MATLAB and Its Applications in Engineering (Elective Course) Course info  Supervised by Professor, Yiru Dai.\n There are six assignments as of 19.06.19. The course covers the following topics:\n Matlab basic operations Numeral and Symbolic calculations Function and plot basics Simulink basics Stateflow basics Optimization toolbox  Weekly solution and codes are available in . md. If you are used to using .html or .doc(x), you can open the corresponding file.\nBest wishes!\n截止19.06.19，共有6次作业，分别关于以下主题：\n 基础操作 数值和符号计算 函数和绘图基础 Simulink基础 Stateflow 基础 优化工具箱  每周解答和代码具体可见.md。如习惯使用.html或是.doc(x)，具体可以打开对应文件。\n祝好！\nCode repo For more details, please refer to my repo hibetterheyj/matlab_basic/coursework in GitHub😀\n","date":1561852800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1561852800,"objectID":"b5768753bcbbb224f7053f9aeb93061b","permalink":"https://yujie-he.github.io/study/2019-matlab/","publishdate":"2019-06-30T00:00:00Z","relpermalink":"/study/2019-matlab/","section":"study","summary":"TJ-100177 MATLAB及其工程应用 | MATLAB and Its Applications in Engineering (Elective Course) Course info  Supervised by Professor, Yiru Dai.\n There are six assignments as of 19.06.19. The course covers the following topics:\n Matlab basic operations Numeral and Symbolic calculations Function and plot basics Simulink basics Stateflow basics Optimization toolbox  Weekly solution and codes are available in . md. If you are used to using .html or .","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" TJ-040388 机电液设计建模 | Digital Modeling and Design of Mechanical-electrical-hydraulic System (Subject Elective Course) Course info  Supervised by Professor, Xiaotian Li\n This is a subject elective course for mechanical engineering students, which are specialized in Mechatronics. This course introduces the modeling of multi-domain engineering systems at a level of detail suitable for design and control system implementation. Topics include modeling using bond graphs, the transformation from the bond graph to block diagram, derivation of state-space models, multi-port energy storage and dissipation, and control-relevant properties.\nCode repo For more details, please refer to my repo hibetterheyj/tju_system_dynamic_modeling_coursework in GitHub 😀\n","date":1559520000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1559520000,"objectID":"da98bcf80ae2f64bd2f920d28c88a1be","permalink":"https://yujie-he.github.io/study/2019-system-modeling-and-design/","publishdate":"2019-06-03T00:00:00Z","relpermalink":"/study/2019-system-modeling-and-design/","section":"study","summary":"TJ-040388 机电液设计建模 | Digital Modeling and Design of Mechanical-electrical-hydraulic System (Subject Elective Course) Course info  Supervised by Professor, Xiaotian Li\n This is a subject elective course for mechanical engineering students, which are specialized in Mechatronics. This course introduces the modeling of multi-domain engineering systems at a level of detail suitable for design and control system implementation. Topics include modeling using bond graphs, the transformation from the bond graph to block diagram, derivation of state-space models, multi-port energy storage and dissipation, and control-relevant properties.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" Final Project  💥Online Viewer: jupyter notebook for final project\n  Title  Enhanced 3D Zonal Segmentation of the Prostate on MRI via Enhanced Weight-Standardization and GroupNorm\n基于的Weight-Standardization和GroupNorm的三维前列腺MRI区块分割\n Abstract  In this final project, I utilized Weight Standardization (WS) as well as GroupNorm to accelerate neural networks training and improve overall segmentation results for 3D Zonal Segmentation of the Prostate on MRI images. WS is targeted at the micro-batch training setting where each GPU typically has only 1-2 images for training. The quantitative experiments have shown that UWG-Net can outperform the performances of 3D U-Net (baseline) with BN trained with small batch sizes with only two more lines of code. The effectiveness of WS is verified on the open-source Prostate Dataset, including 22 training cases and 10 testing cases.\n\nQuantitative experiments on Prostate Dataset. Red, green, and blue fonts denote the first, second, and third best performance among all models. \n\n","date":1578528000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578614400,"objectID":"453995813991317b6c45b0fdf6fd9b64","permalink":"https://yujie-he.github.io/study/2019-deep-learning/final_project/","publishdate":"2020-01-09T00:00:00Z","relpermalink":"/study/2019-deep-learning/final_project/","section":"study","summary":"Final Project  💥Online Viewer: jupyter notebook for final project\n  Title  Enhanced 3D Zonal Segmentation of the Prostate on MRI via Enhanced Weight-Standardization and GroupNorm\n基于的Weight-Standardization和GroupNorm的三维前列腺MRI区块分割\n Abstract  In this final project, I utilized Weight Standardization (WS) as well as GroupNorm to accelerate neural networks training and improve overall segmentation results for 3D Zonal Segmentation of the Prostate on MRI images. WS is targeted at the micro-batch training setting where each GPU typically has only 1-2 images for training.","tags":null,"title":"Overview","type":"docs"},{"authors":[],"categories":[],"content":"Our paper Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters is accepted by the journal of Neural Computing and Applications!\nIt is my first time to publish a regular paper as the first student author. More details will be released soon!\n","date":1578283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578283200,"objectID":"edbf8fa4660063dda7233ceb7679a058","permalink":"https://yujie-he.github.io/post/20-01-ncaa/","publishdate":"2020-01-06T12:00:00+08:00","relpermalink":"/post/20-01-ncaa/","section":"post","summary":"Our paper Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters is accepted by the journal of Neural Computing and Applications!\nIt is my first time to publish a regular paper as the first student author. More details will be released soon!","tags":["journal"],"title":"Jan 2020: Our paper MKCT to appear at Neural Computing and Applications.","type":"post"},{"authors":["Changhong Fu","Yujie He","Fuling Lin","Weijiang Xiong"],"categories":null,"content":"\nMain structure of the proposed tracking approach\n\n","date":1575504000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575504000,"objectID":"3a099303b9e3dae061a1cf46fc4af39e","permalink":"https://yujie-he.github.io/publication/2020_mkct_ncaa/","publishdate":"2020-01-06T00:00:00Z","relpermalink":"/publication/2020_mkct_ncaa/","section":"publication","summary":"In recent years, the correlation filter (CF)-based method has significantly advanced in the tracking for unmanned aerial vehicles (UAV). As the core component of most trackers, CF is a discriminative classifier to distinguish the object from the surrounding environment. However, the poor representation of the object and lack of contextual information have restricted the tracker to gain better performance. In this work, a robust framework with multi-kernelized correlators is proposed to improve robustness and accuracy simultaneously. Both convolutional features extracted from the neural network and hand-crafted features are employed to enhance expressions for object appearances. Then, the adaptive context analysis strategy helps filters to effectively learn the surrounding information by introducing context patches with the GMSD index. In the training stage, multiple dynamic filters with time-attenuated factors are introduced to avoid tracking failure caused by dramatic appearance changes. The response maps corresponding to different features are finally fused before the novel resolution enhancement operation to increase distinguishing capability. As a result, the optimization problem is reformulated, and a closed-form solution for the proposed framework can be obtained in the kernel space. Extensive experiments on 100 challenging UAV tracking sequences demonstrate the proposed tracker outperforms other 23 state-of-the-art trackers and can effectively handle unexpected appearance variations under the complex and constantly changing working conditions.","tags":["Visual tracking","Unmanned aerial vehicles","Multi-kernelized correlators","Adaptive context analysis","Dynamic weighted filters"],"title":"Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters","type":"publication"},{"authors":["Fuling Lin","Changhong Fu","Yujie He","Fan Li"],"categories":null,"content":"\nThe visualization of maximum values on different feature response maps.\n\n","date":1573776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573776000,"objectID":"5282dfadfd7d08c8fadb867603e6c049","permalink":"https://yujie-he.github.io/publication/2020_tot_preprint/","publishdate":"2019-11-15T00:00:00Z","relpermalink":"/publication/2020_tot_preprint/","section":"publication","summary":"Correlation filter (CF)-based trackers have recently de-livered high performance in diverse applications for un-manned aerial vehicles (UAVs). The specific challenges in UAV tracking scenarios pose difficulties in traditional CFs, including camera/object fast motion, viewpoint variations, and background clutter. Most existing approaches employ multiple features to encode the CF but ignore the relevance among these features. Consistency of inter-feature responses limiting CF discriminant power has not been fully explored, especially in complex tracking situations. In this work, a target-oriented UAV tracking approach is proposed to associate various features and repress the difference among responses for better encoding capability. To further ensure the multi-feature response consistency with more focus on the tracked object, the target-oriented regularization is introduced in the optimization problem. Comprehensive experiments on four datasets (UAV123, UAV123@10fps, DTB70, UAVDT) containing 366 sequences with over 200K images show that the proposed TOT method outperforms the other 20 state-of-the-art trackers favorably in accuracy and robustness. For tracking efficiency, TOT achieves a real-time speed of 50 FPS on a single CPU, which can be efficiently applied in UAV onboard processors.","tags":["Visual tracking","Unmanned aerial vehicles","Multi-feature Inconsistency Mining"],"title":"TOT: Target-oriented UAV Tracking via Multi-feature Inconsistency Mining","type":"publication"},{"authors":[],"categories":[],"content":"First time to participate the top robotics conference\u0026mdash;IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019) held on Nov. 4 – 8, 2019 in Macau, China.\nFeel very lucky to talk to the experts, professors, and my fellows!\nOur paper \u0026lsquo;Sample Purification-Aware Correlation Filters for UAV Tracking with Cooperative Deep Features\u0026rsquo; is accepted by the Workshop on Fast Neural Perception and Learning for Intelligent Vehicles and Robotics and won the Best Poster Award!\nFor more details, please refer to SPCF!\n\nMy first time to attend IROS2019 @ Macau\n Keynote by Davide Scaramuzza covering Autonomous Drones Event Cameras \n\n","date":1572840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572840000,"objectID":"b06a9c527d705b63f1d8f86cf734ca2c","permalink":"https://yujie-he.github.io/post/19-11-iros/","publishdate":"2019-11-04T12:00:00+08:00","relpermalink":"/post/19-11-iros/","section":"post","summary":"First time to participate the top robotics conference\u0026mdash;IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019) held on Nov. 4 – 8, 2019 in Macau, China.\nFeel very lucky to talk to the experts, professors, and my fellows!\nOur paper \u0026lsquo;Sample Purification-Aware Correlation Filters for UAV Tracking with Cooperative Deep Features\u0026rsquo; is accepted by the Workshop on Fast Neural Perception and Learning for Intelligent Vehicles and Robotics and won the Best Poster Award!","tags":["conference"],"title":"Nov 2019: Our paper SPCF won the Best Poster Award in the IROS Workshop.","type":"post"},{"authors":["Fuling Lin","Changhong Fu","Yujie He","Fuyu Guo","Qian Tang"],"categories":null,"content":"\nComparison between discriminative correlation filter (DCF) and the proposed BiCF\n\n","date":1568505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568505600,"objectID":"e630d1a4757c9a5a5fff05c0aaa4e9ef","permalink":"https://yujie-he.github.io/publication/2020_bicf_preprint/","publishdate":"2019-09-15T00:00:00Z","relpermalink":"/publication/2020_bicf_preprint/","section":"publication","summary":"Correlation ﬁlters have shown excellent performance in unmanned aerial vehicle (UAV) tracking scenarios due to their high computational efﬁciency. During the UAV tracking process, viewpoint variations are usually accompanied by changes in the object and background appearance, which poses a unique challenge to CF-based trackers. Since the appearance is gradually changing over time, an ideal tracker can not only forward predict the object position but also backtrack to locate its position in the previous frame. There exist errors in the reversibility of the tracking process, which contains the information on the changes in appearance. However, some existing methods do not consider the forward and backward errors while using only the current training sample to learn the ﬁlter. For other ones, the applicants of considerable historical training samples impose a computational burden on the UAV. In this work, a novel bidirectional incongruity-aware correlation ﬁlter, i.e., BiCF tracker, is proposed. By integrating the bidirectional incongruity error into the CF, BiCF can efﬁciently learn the changes in appearance and suppress the inconsistent error. Extensive experiments on 243 challenging image sequences from three UAV datasets (i.e., UAV123, UAVDT, and DTB70) are conducted to demonstrate that the proposed BiCF tracker favorably outperforms other 25 state-of-the-art trackers and achieves a real-time speed of 45.4 FPS on a single CPU, which can be applied in UAV efﬁciently.","tags":["Visual tracking","Unmanned aerial vehicles"],"title":"BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking","type":"publication"},{"authors":["Yujie He","Changhong Fu","Fuling Lin","Yiming Li","Peng Lu"],"categories":null,"content":"\nThe overview of TACF tracker\n\n","date":1568505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568505600,"objectID":"c25f0095de5beeac021aa6d71c67c013","permalink":"https://yujie-he.github.io/publication/2020_tacf_preprint/","publishdate":"2019-09-15T00:00:00Z","relpermalink":"/publication/2020_tacf_preprint/","section":"publication","summary":"Object tracking has become a demanding task for booming unmanned aerial vehicle (UAV) applications in recent years. Although correlation filters (CF) based tracking methods show competitive performance in classic tracking benchmarks, those trackers cannot adequately cope with the dramatic appearance changes caused by the rapid flight of UAV in mid-air. What is more, with limited interpretation to training samples, traditional methods might be easily over-fitted, and lack of local attention ability which undermine the performance as well. Unlike previous works using features fusion or dynamic masking, a practical and straightforward tri-attention strategy is proposed to refine responses and filters learning adaptively. Specifically, three attention strategies are proposed on top of CF-based methods, which model the semantic interdependencies in position, dimension, and surrounding context, respectively. Besides, they can be integrated into correlation filter frameworks for more precise tracking because of lightweight and generality. Through extensive experiments on 173 challenging UAV image sequences, the proposed tracker demonstrates competitive tracking accuracy and robustness, achieving better performance than other 12 state-of-the-art trackers under challenging situations.","tags":["Visual tracking","Unmanned aerial vehicles","Attention mechanisms"],"title":"Tri-Attention Correlation Filter for Effective UAV Object Tracking","type":"publication"},{"authors":["Changhong Fu","Fuling Lin","Fan Li","Yujie He"],"categories":null,"content":"\nComparison between traditional CF-based and proposed SPCF tracker\n\n","date":1567209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567209600,"objectID":"885aa35a9654e3a8444e0e183be373c5","permalink":"https://yujie-he.github.io/publication/2019_spcf_irosw/","publishdate":"2019-08-31T00:00:00Z","relpermalink":"/publication/2019_spcf_irosw/","section":"publication","summary":"Correlation Filters (CF) have recently demonstrated promising performance in terms of rapidly tracking objects for unmanned aerial vehicles (UAV) in different types of UAV tracking tasks. The strength of the approach comes from its ability to learn how the object is changing over time efficiently. However, due to heavy dependence on the quality of the training set and the lack of real negative training samples, the object appearance model may be easily interfered by the corrupted training samples, which can result in suboptimal performance. Besides, limited by the representation of a single feature, the tracking model may fail to cope with the complex surrounding environment and considerable appearance variation of the object. In this work, the principal causes behind the problems of the abundance of object representation and purity of training samples have been tackled, to simultaneously improve both discriminative power and anti-disturbance capability of the tracking model. Comprehensive experiments on 100 challenging UAV image sequences have demonstrated that the novel sample purifying tracker based on cooperative features learning, i.e., SPCF tracker, outperforms 15 state-of-the-art trackers in terms of efficiency, robustness, and accuracy. To the best of our knowledge, the presented SPCF tracker is designed for object tracking and employed in UAV tracking tasks for the first time.","tags":["Correlation filter","Unmanned aerial vehicles","Sample purification"],"title":"Sample Purification-Aware Correlation Filters for UAV Tracking with Cooperative Deep Features","type":"publication"},{"authors":null,"categories":null,"content":" Teaching Assistant from Sep. 2018 - Jan. 2019\n  Assisted first-year students major in Industrial Design to get started Arduino Hardware and Programming\n Designed a series of the electromechanical modules for Industrial Design students\n Gave lectures on basic mechanical principle with Arduino hardware and programming and advanced RGBD sensors for the semester project\n  The following video is Mechatronics Module Experiments.\n\n \n","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"5fb85218b7c762be752eebb403211af0","permalink":"https://yujie-he.github.io/project/2019-tongji-ta/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/project/2019-tongji-ta/","section":"project","summary":"Acted as TA for freshmen in [College of Design \u0026 Innovation](http://tjdi.tongji.edu.cn/)","tags":["Mechatronics"],"title":"Teaching Assistant in Open Source Hardware and Programming","type":"project"},{"authors":null,"categories":null,"content":" Powertrain Group Leader from Sep. 2016 - Dec. 2018\n  Designed and optimized the overall powertrain system to ensure China\u0026rsquo;s first leading four-wheel-drive Formula Student Racecar, achieving an 8\\% efficiency and 10\\% lightweight improvement Participated FSEC 2017 - 2018 and SFJ 2018 as Chief Powertrain Engineer, contributing to DIAN Racing‘s win in first place in Engineering Design and Efficiency Prize, and Best Powertrain Award from 2017 to 2018  The following video is virtual assembly of DRe18，which was what I worked for as Powertrain Group Leader.\n\n  Design Report Final @ FSEC19 \n","date":1546214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546214400,"objectID":"82d14568390f43b7be1a421e74f001ca","permalink":"https://yujie-he.github.io/project/2018-dian-racing/","publishdate":"2018-12-31T00:00:00Z","relpermalink":"/project/2018-dian-racing/","section":"project","summary":"Built First leading 4WD Formula Student Racecar in China.","tags":["Mechatronics","Racecar"],"title":"DIAN Racing Formula Student Electric Team","type":"project"},{"authors":null,"categories":null,"content":" Robotics Algorithm Development Intern from Jul. 2018 - Aug. 2018\n  Implemented sensor fusion between Pandar40 (a 40-channel LiDAR) and gyroscope and achieved a 5% accuracy improvements on top of state-of-the-art SLAM framework and drew a 3D point cloud map of Tongji University Jiading Campus below 10m Deployed control, decision, and communication algorithms for a self-developed skid steer wheel robot, realizing autonomous navigation and obstacle avoidance in a $ 300 m^2 $ workspace  \n Indoor SLAM @ Hesai\n\n Debugging the robot\n\n Jiading Campus Satellite Map corresponding to the map generated from Pandar40 \n\n","date":1546214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546214400,"objectID":"2cf2900a21859645e66bc3bb95d82458","permalink":"https://yujie-he.github.io/project/2018-hesai-internship/","publishdate":"2018-12-31T00:00:00Z","relpermalink":"/project/2018-hesai-internship/","section":"project","summary":"Implemented Outdoor SLAM @ Tongji Jiading Campus and Indoor Autonomous Navigation .","tags":["Robotics","Computer Vision","LiDAR"],"title":"SLAM and Autonomous Navigation for Skid Steer Wheel Robot","type":"project"},{"authors":null,"categories":null,"content":" Project Manager \u0026amp; Mechanical Development Leader from Oct. 2016 - Jun. 2018\n  Designed two main robots to participate in national mobile robot competition, RoboMaster, achieving lightweight and stability of the chassis and 3DOF pan-tilt mechanism and multi-robot interaction Optimized structural design to enhance operation stability and achieve lightweight, enable the robots flexible operation and combating under complicated circumstances  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"26fb77baca14eeca774e060f789d6ff1","permalink":"https://yujie-he.github.io/project/2018-super-power/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/2018-super-power/","section":"project","summary":"Designed robots to combat in RoboMaster.","tags":["Mechatronics","Robotics"],"title":"Super Power Robot Team","type":"project"}]